{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n",
      "Fetching pages: 100%|##########| 91/91 [00:12<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 91 documents.\n",
      "In T#, you can access haptics via the StudioHaptics class. This class provides several static methods to play different haptic feedback patterns. Here are some examples:\n",
      "\n",
      "1. To play the haptic feedback for selection:\n",
      "```T#\n",
      "StudioHaptics.PlayHapticSelection();\n",
      "```\n",
      "\n",
      "2. To play the haptic feedback for success:\n",
      "```T#\n",
      "StudioHaptics.PlayHapticSuccess();\n",
      "```\n",
      "\n",
      "3. To play the haptic feedback for warning:\n",
      "```T#\n",
      "StudioHaptics.PlayHapticWarning();\n",
      "```\n",
      "\n",
      "These methods will trigger haptic feedback on supported devices.\n",
      "\n",
      "Source: [T# Haptics & Extensions](https://wiki.letsterra.com/coding-using-t/t-haptics-and-extensions)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import asyncio\n",
    "import nest_asyncio  # Import nest_asyncio\n",
    "import httpx  # Import httpx for handling HTTP requests\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import GitbookLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize ChatOpenAI with the model\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# GitBook URL\n",
    "gitbook_url = \"https://wiki.letsterra.com/\"  # Replace with your GitBook URL\n",
    "\n",
    "def load_gitbook_content():\n",
    "    # Load GitBook content\n",
    "    loader = GitbookLoader(gitbook_url, load_all_paths=True)\n",
    "    all_documents = loader.load()  # No need to await\n",
    "    return all_documents\n",
    "\n",
    "async def main():\n",
    "    # Load documents\n",
    "    all_documents = load_gitbook_content()  # Call the synchronous function\n",
    "    print(f\"Loaded {len(all_documents)} documents.\")  # Debugging line\n",
    "\n",
    "    # Check if any documents were loaded\n",
    "    if not all_documents:\n",
    "        print(\"No documents were loaded. Please check the GitBook URL or the loading process.\")\n",
    "        return\n",
    "\n",
    "    # Split the documents into manageable chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=250, add_start_index=True\n",
    "    )\n",
    "    all_splits = text_splitter.split_documents(all_documents)\n",
    "\n",
    "    # Create a new vector store from the documents\n",
    "    vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "    # Create a retriever from the vector store\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "    # Define the refined system prompt\n",
    "    system_prompt = (\n",
    "        \"You are an assistant for question-answering tasks related to game development using a custom game engine called Terra Creator Studio. \"\n",
    "        \"Your primary responsibilities include: \"\n",
    "        \"- Providing complete function implementations in T# when a script or code snippet is requested. \"\n",
    "        \"- Ensure the function code is self-contained and can be directly copied into Terra Studio. \"\n",
    "        \"- Prioritize using or modifying existing wrapper functions for logic templates, or combine multiple wrapper functions, rather than writing new functions from scratch unless no suitable options exist. \"\n",
    "        \"Follow these guidelines: \"\n",
    "        \"- Most syntax is similar to C#, but identify differences by examining access wrappers and methods. \"\n",
    "        \"- Refer to the 'T# Don'ts' section of the context document to avoid common pitfalls and differences from Unity C# syntax. \"\n",
    "        \"- If a question requests a script, provide complete T# function code that can be copied directly into Terra Studio. \"\n",
    "        \"Consistency is key: \"\n",
    "        \"- Ensure responses are consistent; similar questions should yield similar answers, even if asked multiple times. \"\n",
    "        \"- Always refer to the provided context below. \"\n",
    "        \"If you encounter questions about features in Terra Studio: \"\n",
    "        \"- Search the relevant portion of the context and provide a relevant answer. \"\n",
    "        \"Important: \"\n",
    "        \"- Always double-check the context document to ensure your answers are accurate and not based on hallucination. \"\n",
    "        \"- Verifying information is more important than providing a quick but incorrect answer. \"\n",
    "        \"If you cannot find an answer in the T# documentation, state that you don't know. \"\n",
    "        \"Your answers should be: \"\n",
    "        \"- Clear, concise, and suitable for novice developers. \"\n",
    "        \"- Always include the source of the information used in your response from the context, and ensure the sources are accurate. \"\n",
    "        \"- If you cannot provide a source, please indicate that the source is not available.\"\n",
    "        \"\\n\\n\"\n",
    "        \"{context}\\n\\n\"\n",
    "        \"Sources:\\n{sources}\"\n",
    "    )\n",
    "\n",
    "    # Create the chat prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the question-answer chain\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "    # Store for chat history\n",
    "    store = {}\n",
    "    def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "        if session_id not in store:\n",
    "            store[session_id] = ChatMessageHistory()\n",
    "        return store[session_id]\n",
    "\n",
    "    # Wrap the RAG chain with message history management\n",
    "    conversational_rag_chain = RunnableWithMessageHistory(\n",
    "        rag_chain,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        output_messages_key=\"answer\",\n",
    "    )\n",
    "\n",
    "    session_id = \"ashw0014\"  # Unique session ID for the conversation\n",
    "\n",
    "    # Test the retrieval-augmented generation chain\n",
    "    input_question = \"How do I access haptics via T# code\"\n",
    "    try:\n",
    "        retrieved_docs = retriever.invoke(input_question)\n",
    "\n",
    "        # Check if any documents were retrieved\n",
    "        if not retrieved_docs:\n",
    "            print(\"No documents retrieved. Please check your query.\")\n",
    "        else:\n",
    "            context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "            # Create a more informative sources output\n",
    "            sources = \"\\n\".join(f\"- Source: {doc.metadata['source']}\\n  Content: {doc.page_content[:300]}...\" for doc in retrieved_docs)  # Show first 300 characters\n",
    "\n",
    "            # Retrieve the chat history for the session\n",
    "            chat_history = get_session_history(session_id)\n",
    "\n",
    "            # Include chat history in the input\n",
    "            input_with_history = \"\\n\".join([f\"User: {msg['input']}\\nAI: {msg['answer']}\" for msg in chat_history.messages]) + f\"\\nUser: {input_question}\"\n",
    "\n",
    "            formatted_prompt = system_prompt.format(context=context, sources=sources)\n",
    "\n",
    "            response = conversational_rag_chain.invoke(\n",
    "                {\"input\": input_question, \"context\": context, \"sources\": sources},\n",
    "                config={\"configurable\": {\"session_id\": session_id}}\n",
    "            )\n",
    "\n",
    "            # Store the new question and answer in the chat history\n",
    "            chat_history.messages.append({\"input\": input_question, \"answer\": response[\"answer\"]})\n",
    "\n",
    "            print(response[\"answer\"])\n",
    "\n",
    "    except httpx.ConnectError as e:\n",
    "        print(f\"Connection error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
